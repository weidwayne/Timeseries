{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Deep Learning Timeseries](https://medium.com/towards-data-science/the-best-deep-learning-models-for-time-series-forecasting-690767bc63f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [N-BEATS](https://arxiv.org/pdf/1905.10437.pdf) (Neural Basis Expansion Analysis Time Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution\n",
    "- show that pure DL using no time-series specific conmponents outperforms well-established stat approaches\n",
    "- Interpretable DL for Time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement \n",
    "Univariate point forcasting problem in discrete time\n",
    "- H: forecast horizon\n",
    "- T: observed series history $[y_1, \\ldots, y_T]$\n",
    "- t: lookback window $x \\in \\mathbb{R}^t = [y_{T-t+1},\\ldots,y_T]$\n",
    "- tasks: to predict the vector of future values $\\textbf{y} \\in \\mathbb{R}^H = [y_{T+1},\\ldots, y_{T+H}]$\n",
    "- $\\hat y$: forecast of y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-BEATS\n",
    "![alt_text](https://miro.medium.com/max/700/1*qWe4P1BDLlDw79bjuhGXXQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Block\n",
    "- backcast: produce an estimate of $x_l$ with the ultimate goal of helping the downsteream blocks by removing components of their input that are helpful for forecasting\n",
    "- forecast: ultimate gola of optimizing the accuracy of the partial forcast $\\hat y_l$ by properly mixing the bassis vector supplied by $g_l^f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doubly Residual Stacking\n",
    "$$ x_l = x_{l-1} - \\hat x_{l-1}$$\n",
    "$$ \\hat y = \\sum_l \\hat y_l$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretablity\n",
    "The interpretable architecture can be constructed by adding strcutrue to basis layers at stack level. practitioners often use the decomp of time series into trend and seasonablity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [DeepAR](https://arxiv.org/pdf/1704.04110.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution \n",
    "\n",
    "- RNN for probabilistic forcasting, which incorporates a negative binomial likelihood for count data as well as special treatment for the case where the magnitudes of the time series vary widely\n",
    "- demonstrate this model produces accurate proba forecasts across a range of input characteristics\n",
    "- Key advantages\n",
    "    - learns seasonal beh and dependencies on given covariates across time series, minimizing manual feature engineering is needed to capture complex, group-dependent havaior\n",
    "    - makes probabilistic forecasts in the form of Monte Carlo samples that can be used to compute consistent quantile estimates for all sub-ranges in prediction horizon\n",
    "    - provides forcasts for items with little or no history by learning from similar items\n",
    "    - does not assume Gaussian noise, but can incoporate a wide range of likelihood functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model \n",
    "- $z_{i,t}$: time series i at time t\n",
    "- $x_{i,1:T}$: covariates that are assumed to be known for all time points\n",
    "\n",
    "An autoregressive recurrent network airchitecture Model the conditional distribution \n",
    "$$P(z_{i,t_0:T}|z_{i,1:t_0-1},x_{i,1:T})$$\n",
    "assuming the model distribution $Q_\\theta$ consists of a product of likelihood factors \n",
    "$$Q_\\Theta(z_{i,t_0:T}|z_{i,1:t_0-1},x_{i,1:T}) = \\prod_{t=t_0}^T Q_\\Theta(z_{i,t}|z_{i,1:t-1},x_{i,1:T}) = \\prod_{t=t_0}^T \\ell(z_{i,t}|\\theta(\\mathbf{h_{i,t},\\Theta}))$$\n",
    "\n",
    "parameterized by the output of an autoregressive recurrent network \n",
    ">$$\\mathbf{h}_{i,t} = h(\\mathbf{h}_{i,t}, z_{i,t-1}, x_{i,t},\\Theta)$$\n",
    "\n",
    "![alt_text](https://miro.medium.com/max/700/1*RJV1g4pH5TuFH9VXXpRJUg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood model \n",
    "The likelihood $\\ell(z|\\theta)$ shoudl be chosen to match the stat prop of the data, in this approach, the network directly predicts all parameters $\\theta$ (mean and variance) of the prob distribution for the next time point\n",
    "\n",
    "Gaussian likelihood for real-valued data\n",
    "\n",
    "negative-hinomial likelihood for positive count data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling handling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [Spacetimeformer](https://arxiv.org/pdf/2109.12218.pdf)\n",
    "Key pieces\n",
    "- Long-range Transformers\n",
    "    - Performer for long-range sequence\n",
    "- Spatial-Tempoeral Forecasting\n",
    "![](.\\img\\spatio-temporal_attention.png)\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*zNsA32-eJHeP1Am9ipLB9A.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.[Temporal Fusion Transformer](https://arxiv.org/pdf/1912.09363.pdf)\n",
    "all autoregressive methods (ARIMA) including DeepAR lacks the capability to incorporate covariates only up to present time\n",
    "\n",
    "https://towardsdatascience.com/temporal-fusion-transformer-googles-model-for-interpretable-time-series-forecasting-5aa17beb621\n",
    "\n",
    "- rich number of features\n",
    "    - time-dependent data with known inputs into the future\n",
    "    - time-dependent data known only up to the present\n",
    "    - static variables (time-invariant) features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution \n",
    "- **rich features**: supports 3 types of features: \n",
    "    - temporal data with known inputs into the future\n",
    "    - temporal data known only up to the present \n",
    "    - exogenous categorical/static varaibles, known as time-invariant features\n",
    "- **Heterogeneous time series**: supports training on multiple time series, coming from different distr. TFT splits processing into 2 parts: local processing which focuses on the characteristics of specific events and global processing which captures the collective characteristics of all time series\n",
    "- **multi-horizon forecasting**\n",
    "- **interpretability**: Transformer-based architecture, by taking adv of self-attention, this model presents a novel multi-head attention mechanism which when analyzed, provides extra insights on feature importances. (counterexample of MQRNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model \n",
    "1. $\\textbf{Gating Mechanism}$ to skip over any unused compo- nents of the architecture, providing adaptive depth and network complexity to accommodate a wide range of datasets and scenarios\n",
    "2. $\\textbf{Variable selection network}$ to select relevant input variables at each time step\n",
    "3. $\\textbf{Static covariate encoders}$ to integrate static features into the network, through the encoding of context vectors to condition temporal dynamics\n",
    "4. $\\textbf{Temporal processing}$ to learn both long- and short- term temporal relationships from both observed and known time-varying inputs. A sequence-to-sequence layer is employed for local processing, whereas long- term dependencies are captured using a novel inter- pretable multi-head attention block\n",
    "5. $\\textbf{Prediction intervals}$ via quantile forecasts to deter- mine the range of likely target values at each prediction horizon\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*7rXe_MVn5QI9oLP2vrMdvQ.png)\n",
    "\n",
    "**Model inputs**:\n",
    "\n",
    "- $k$ lookback window: \n",
    "- $\\tau_{max}$ step ahead window\n",
    "- Observed past input $x$ in the time period $[t-k,\\ldots,t]$\n",
    "- Future known inputs $x$ in the time period $[t+1,\\ldots,t+\\tau_{max}]$\n",
    "- a set of static variables $s$\n",
    "- Target variable $y$ also spans the time window $[t+1,\\ldots,t+\\tau_{max}]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gated Residual Network\n",
    "![](https://miro.medium.com/max/342/1*9eIgK7rVAwnXyHje2YKjkA.png)\n",
    "- two types of activation functions called ELU (Exponential Linear Unit) and GLU (Gated Linear Units). GLU was first used in the [Gated Convolutional Networks](https://arxiv.org/pdf/1612.08083v3.pdf) architecture for selecting the most important features for predicting the next word. In fact, both of these activation functions help the network understand which input transformations are simple and which require more complex modeling\n",
    "- The final output passes through standard Layer Normalization. The GRN also contain a residual connection, meaning that the network could learn, if necessary, to skip the input entirely. In some cases, depending where the GRN is situated, the network can also make use of static variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Selection Network (VSN)\n",
    "\n",
    "VSN utilized GRN under the hood for its filtering capability\n",
    "- At time t the flattened vector of all past inputs (called $\\Xi_t$) of the corresponding lookback period is fed through a GRN unit (in blue) and then a softmax function, producing a normalized vector of weights $u$\n",
    "- each feature passes thru its own GRN, producing a processed vector called $\\xi_t$, one for every variable\n",
    "- output a linear combo of $\\xi_t$ and $u$\n",
    "- The GRN for each feature is the same across all time steps during the same lookback period\n",
    "- VSN for static variables does not take into acount the context vector $c$\n",
    "\n",
    "![](https://miro.medium.com/max/344/1*mcf8w_N_kT6Jln94TXFC7w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretable Multi-Head Attention\n",
    "shared value weights across all heads\n",
    ">$$ \\tilde{H} = \\frac{1}{m_H} \\sum^{m_H}_{h=1} A(Q W^{(h)}_Q, K W^{(h)}_K) V W_V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Encoder Decoder Layer\n",
    "1. produce context-aware embeddings by feeding known inputs to encoder while unknown future inputs into decoder. Similar to the positional encoding used in Transformer\n",
    "2. merge the context-aware embeddings produced by LSTM with context vectors $c$ of static variables, by initializing the hidden state and cell state with $c_h$ and $c_c$ vectors from static covariate encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. locality enhancement with seq2seq layer\n",
    "This is similar to positional encoding used in classic Transformer in order to account for all types of inputs. The known inputs are fed into the encoder, while the unknown future inputs are fed into the decoder. \n",
    "##### 2. static enrichment layer\n",
    "\n",
    "##### 3. Temporal self-attention layer\n",
    "all static-enriche temporal features are first grouped into a single matrix $\\Theta = [\\theta(t,-k),\\ldots,\\theta(t,\\tau)]^T$ and multi-head attention is applied \n",
    ">$$ B(t) = interpretableMultiHead(\\Theta(t),\\Theta(t),\\Theta(t))$$\n",
    "\n",
    "##### 4. position-wise feed-forward layer\n",
    "apply aditional non-linear processing to outputs of self-attetntion layer, where the weights of GRN are shared across teh entire layer. We also apply a gated residual connection which skps over the entire transformer block, providing direct path to the seq2seq layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Multi-horizon Quantile R(C)NN](https://arxiv.org/abs/1711.11053)\n",
    "a Seq2Seq framework than genrates multi-horizon Quantile forecasts. It is designed to solve the large scale tme series regression problem:\n",
    ">$$p(y_{t+k,\\dots, y_{t+1}}|y_{:t}, x^h_{:t}, x^f_{t:}, x^s)$$\n",
    "- $x^h_{:t}$ termporal covariates available in history\n",
    "- $x^f_{t:}$ temporal covariates in the future\n",
    "- $x^s$ static time-invariant features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contribution\n",
    "- efficient training schedume for the combination of sequential NN and Multi-horizon forecast\n",
    "- network sub-structure to accommondate future information, including the alignment of shifting seasonality and know events that cause large spikes and dips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method\n",
    "![](img\\MQRNN.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture\n",
    "- LSTM encoder: encode all history into hidden states $h_t$\n",
    "\n",
    "- global MLP: summarize the encoder output plus all future inputs into 2 contexts: a series of horizon-specific contexts $c_{t+k}$ for each of the $K$ future points, and a horizon-agnostic context $c_a$ which captures common information\n",
    "\n",
    "- local MLP combines corresponding future input and the two contexts from global MLP, outputs required quatiles for that sepecific fture time steps.\n",
    "    - carries network-structural awareness of the temporal distance btw a forecast creation time point and a specific horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Scheme\n",
    "our framework creates Multi-Horizon forecasts by placing a series of decoders, with shared parameters, at each recurrent layer (time point) in the encoder, and computes the loss against the cor- responding targets (future series relative to that time point\n",
    "\n",
    "Then one back-propagation-through-time can gather the multi-horizon error gradients of different FCTs in one pass over a sample, with little additional cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Deep State Space Models for Time Series Forecasting](https://proceedings.neurips.cc/paper/2018/file/5cf68969fb67aa6082363a6d4e6468e2-Paper.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98528e6a084d503ff5d5003dddb740d32265307d7f7b32e3270d07060d4a8462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
